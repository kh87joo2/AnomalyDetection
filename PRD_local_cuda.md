# PRD - Local CUDA Migration Track

Version: v1.0
Date: 2026-02-23
Owner: local-cuda track

## 1. Background
The current project was validated in Google Colab and many successful outputs were created in temporary `/content` paths. The next phase is to move to a local GPU workstation and run the same training/inference/validation/dashboard flow in a stable, repeatable environment.

## 2. Problem Statement
- Colab runtime is temporary and quota-dependent.
- Artifacts generated in `/content` are not durable by default.
- Notebook flow includes Colab-specific code paths that are not ideal for local operation.
- Local execution should be independent from Colab while preserving reproducibility.

## 3. Product Goal
Create a local-first execution track that:
- keeps existing Colab work intact,
- runs fully on a local CUDA machine,
- uses repository-relative paths,
- preserves the same functional outputs (checkpoints, logs, scoring, dashboard state).

## 4. Scope
In scope:
- New local planning docs and task queue.
- Local config variants for PatchTST and SwinMAE.
- Local notebook variants without `/content` dependency.
- Import process for existing Colab artifacts.
- End-to-end local verification commands.

Out of scope:
- Model architecture redesign.
- New backend services.
- Production deployment automation.
- Dataset labeling or new domain adaptation work.

## 5. Target Users
- Primary: local developer/operator with CUDA workstation.
- Secondary: collaborators who need deterministic local reruns.

## 6. Functional Requirements
FR-01: Existing baseline docs and code must remain available in this cloned workspace.
FR-02: Local config files must avoid hardcoded Colab paths.
FR-03: Local notebooks must run with local paths and no `google.colab` dependency.
FR-04: Training commands must produce checkpoints in `checkpoints/`.
FR-05: Training must produce loss artifacts in `artifacts/loss/`.
FR-06: Validation pipeline must pass with local references.
FR-07: Dashboard export must generate `training_dashboard/data/dashboard-state.json`.
FR-08: Run history snapshots must be persistable in `training_dashboard/data/runs/`.

## 7. Non-Functional Requirements
NFR-01: Reproducibility via pinned requirements and explicit commands.
NFR-02: Path portability via repo-relative defaults.
NFR-03: Compatibility with Python 3.11+ and CUDA-enabled PyTorch.
NFR-04: No destructive changes to original Colab-track documents.
NFR-05: New artifacts should be generated by script/CLI, not manual patching.

## 8. Success Criteria
SC-01: Both training commands complete on local GPU.
SC-02: Both scoring smoke commands succeed using local checkpoints.
SC-03: `python -m pipelines.validate_training_outputs --repo-root .` completes with all required checks passing (or explicit known exceptions documented).
SC-04: `python -m pipelines.export_training_dashboard_state --repo-root . --out training_dashboard/data/dashboard-state.json --persist-run-history --run-id local_run_001` succeeds.
SC-05: Dashboard can be opened locally and render the exported state.

## 9. Deliverables
- `PRD_local_cuda.md`
- `TRD_local_cuda.md`
- `Todo_local_cuda.md`
- local config variants
- local notebook variants
- updated runbook section for local GPU flow

## 10. Risks and Mitigations
Risk: CUDA/PyTorch mismatch on local machine.
Mitigation: Verify torch CUDA metadata before training.

Risk: Colab artifacts missing or inconsistent.
Mitigation: Define required artifact checklist and recovery order.

Risk: Path drift between CLI and notebooks.
Mitigation: Enforce one canonical path policy based on repository root.

## 11. Milestones
M1: Planning docs and task routing prepared.
M2: Local configs and notebook split completed.
M3: Local E2E training/inference/validation complete.
M4: Dashboard state and run history verified.
